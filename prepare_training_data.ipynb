{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from agent_code.training_data.memory import ReplayMemory\n",
    "import torch\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple, deque\n",
    "\n",
    "# first we extract all information from the memory\n",
    "ActionWithEvent = namedtuple(\"Transition\", (\"game_state\", \"state\", \"action\", \"score\", \"events\", \"round_reward\", \"discounted_reward\"))\n",
    "# then we change it into network_input, action, discounted_reward\n",
    "Datapoint = namedtuple(\"Datapoint\", (\"network_input\", \"action\", \"discounted_reward\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay = ReplayMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CPU_Unpickler(pickle.Unpickler):\n",
    "    def find_class(self, module, name):\n",
    "        if module == 'torch.storage' and name == '_load_from_bytes':\n",
    "            return lambda b: torch.load(io.BytesIO(b), map_location='cpu')\n",
    "        else:\n",
    "            return super().find_class(module, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from collections import deque\n",
    "data = deque()\n",
    "with open(\"training_data.pt\", \"rb\") as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transition(state={'round': 1, 'step': 1, 'field': array([[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        -1],\n",
       "       [-1,  0,  0,  0,  1,  1,  0,  1,  1,  0,  1,  1,  0,  0,  0,  0,\n",
       "        -1],\n",
       "       [-1,  0, -1,  1, -1,  0, -1,  0, -1,  1, -1,  0, -1,  1, -1,  0,\n",
       "        -1],\n",
       "       [-1,  0,  1,  1,  1,  1,  1,  1,  1,  1,  0,  0,  1,  1,  1,  1,\n",
       "        -1],\n",
       "       [-1,  0, -1,  1, -1,  0, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1,\n",
       "        -1],\n",
       "       [-1,  0,  0,  1,  1,  1,  1,  1,  1,  0,  0,  1,  1,  1,  0,  1,\n",
       "        -1],\n",
       "       [-1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1,\n",
       "        -1],\n",
       "       [-1,  1,  0,  1,  1,  0,  1,  0,  0,  0,  0,  1,  1,  1,  0,  1,\n",
       "        -1],\n",
       "       [-1,  0, -1,  1, -1,  1, -1,  0, -1,  1, -1,  0, -1,  1, -1,  0,\n",
       "        -1],\n",
       "       [-1,  1,  1,  0,  1,  1,  1,  1,  1,  1,  1,  0,  1,  1,  1,  1,\n",
       "        -1],\n",
       "       [-1,  1, -1,  1, -1,  1, -1,  1, -1,  0, -1,  1, -1,  1, -1,  1,\n",
       "        -1],\n",
       "       [-1,  1,  1,  1,  1,  1,  1,  1,  0,  1,  1,  1,  1,  1,  1,  1,\n",
       "        -1],\n",
       "       [-1,  1, -1,  1, -1,  1, -1,  1, -1,  0, -1,  1, -1,  1, -1,  1,\n",
       "        -1],\n",
       "       [-1,  0,  1,  1,  0,  1,  0,  1,  0,  0,  1,  1,  1,  1,  1,  1,\n",
       "        -1],\n",
       "       [-1,  0, -1,  1, -1,  1, -1,  1, -1,  1, -1,  0, -1,  1, -1,  0,\n",
       "        -1],\n",
       "       [-1,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  0,  0,  0,\n",
       "        -1],\n",
       "       [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        -1]], dtype=int64), 'self': ('training_data', 0, True, (1, 1)), 'others': [('rule_based_agent_0', 0, True, (15, 15)), ('rule_based_agent_1', 0, True, (15, 1)), ('rule_based_agent_2', 0, True, (1, 15))], 'bombs': [], 'coins': [], 'user_input': None, 'explosion_map': array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.]])}, action='DOWN', next_state={'round': 1, 'step': 1, 'field': array([[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        -1],\n",
       "       [-1,  0,  0,  0,  1,  1,  0,  1,  1,  0,  1,  1,  0,  0,  0,  0,\n",
       "        -1],\n",
       "       [-1,  0, -1,  1, -1,  0, -1,  0, -1,  1, -1,  0, -1,  1, -1,  0,\n",
       "        -1],\n",
       "       [-1,  0,  1,  1,  1,  1,  1,  1,  1,  1,  0,  0,  1,  1,  1,  1,\n",
       "        -1],\n",
       "       [-1,  0, -1,  1, -1,  0, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1,\n",
       "        -1],\n",
       "       [-1,  0,  0,  1,  1,  1,  1,  1,  1,  0,  0,  1,  1,  1,  0,  1,\n",
       "        -1],\n",
       "       [-1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1, -1,  1,\n",
       "        -1],\n",
       "       [-1,  1,  0,  1,  1,  0,  1,  0,  0,  0,  0,  1,  1,  1,  0,  1,\n",
       "        -1],\n",
       "       [-1,  0, -1,  1, -1,  1, -1,  0, -1,  1, -1,  0, -1,  1, -1,  0,\n",
       "        -1],\n",
       "       [-1,  1,  1,  0,  1,  1,  1,  1,  1,  1,  1,  0,  1,  1,  1,  1,\n",
       "        -1],\n",
       "       [-1,  1, -1,  1, -1,  1, -1,  1, -1,  0, -1,  1, -1,  1, -1,  1,\n",
       "        -1],\n",
       "       [-1,  1,  1,  1,  1,  1,  1,  1,  0,  1,  1,  1,  1,  1,  1,  1,\n",
       "        -1],\n",
       "       [-1,  1, -1,  1, -1,  1, -1,  1, -1,  0, -1,  1, -1,  1, -1,  1,\n",
       "        -1],\n",
       "       [-1,  0,  1,  1,  0,  1,  0,  1,  0,  0,  1,  1,  1,  1,  1,  1,\n",
       "        -1],\n",
       "       [-1,  0, -1,  1, -1,  1, -1,  1, -1,  1, -1,  0, -1,  1, -1,  0,\n",
       "        -1],\n",
       "       [-1,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  0,  0,  0,\n",
       "        -1],\n",
       "       [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        -1]], dtype=int64), 'self': ('training_data', 0, True, (1, 2)), 'others': [('rule_based_agent_0', 0, True, (14, 15)), ('rule_based_agent_1', 0, True, (14, 1)), ('rule_based_agent_2', 0, True, (2, 15))], 'bombs': [], 'coins': [], 'user_input': None, 'explosion_map': array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0.]])}, reward=['MOVED_DOWN'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "\n",
    "data = deque(chain.from_iterable(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"training_data.pt\", \"wb\") as f:\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay.load_from_file('agent_code/training_data/training_data_solo.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "840098"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(replay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "memories = replay.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import events as e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(memory):\n",
    "    return memory.state[\"self\"][1]\n",
    "\n",
    "def get_round(memory):\n",
    "    return memory.state[\"round\"]\n",
    "\n",
    "def get_step(memory):\n",
    "    return memory.state[\"step\"]\n",
    "\n",
    "def get_events(memory):\n",
    "    return memory.reward\n",
    "\n",
    "def get_reward_from_events(events):\n",
    "    rewards = {\n",
    "        e.CRATE_DESTROYED: 0.1,\n",
    "        e.KILLED_SELF: -1,\n",
    "        e.GOT_KILLED: -4,\n",
    "        e.INVALID_ACTION: -0.1,\n",
    "        e.COIN_COLLECTED: 1,\n",
    "        e.KILLED_OPPONENT: 5,\n",
    "    }\n",
    "    reward = sum([rewards.get(event, 0.) for event in events])\n",
    "    return round(reward, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MOVED_UP']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_events(memories[1481])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4839823071792934\n",
      "0.6319257\n"
     ]
    }
   ],
   "source": [
    "# discount factor reduces the importance of future rewards\n",
    "# after 10 steps the reward is only 50% of the original reward\n",
    "discount_factor = 0.93\n",
    "print(discount_factor ** 10)\n",
    "# score normalization\n",
    "# score should be between -1 and 1, since player kills normally give 5 score and coins 1, we normalize by dividing by 5\n",
    "# we will have to restrict the score to be between -1 and 1\n",
    "# additionally, since multiple rewards can be given at the same time, and the discounted score from the future is added to the current score, we need to divide by an additional factor\n",
    "# additional factor is 2 so that the score maxes out if you get 2 kills at once\n",
    "score_reduction_factor = 1 / (5 * 2)\n",
    "print(5 * score_reduction_factor * discount_factor + 1 * score_reduction_factor * discount_factor**2 + 1 * score_reduction_factor * discount_factor**3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards = np.zeros(len(memories))\n",
    "\n",
    "for idx, memory in enumerate(memories):\n",
    "    reward = get_reward_from_events(memory.reward)\n",
    "    rewards[idx] = reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "memories.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_code.mcts.game_state import state_from_game_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions_with_event = deque()\n",
    "running_reward = 0\n",
    "for idx, memory in enumerate(memories):\n",
    "    if memory.next_state is None:\n",
    "        running_reward = 0\n",
    "    \n",
    "    reward = get_reward_from_events(memory.reward)\n",
    "    running_reward = discount_factor * running_reward + reward\n",
    "\n",
    "    state = state_from_game_state(memory.state)\n",
    "\n",
    "    bounded_running_reward = min(1, max(-1, running_reward))\n",
    "\n",
    "    score = memory.next_state[\"self\"][1] if memory.next_state else memory.state[\"self\"][1]\n",
    "\n",
    "    action_with_event = ActionWithEvent(\n",
    "        game_state=memory.state,\n",
    "        state=state,\n",
    "        action=memory.action,\n",
    "        score=score,\n",
    "        events=memory.reward,\n",
    "        round_reward=reward,\n",
    "        discounted_reward=bounded_running_reward\n",
    "    )\n",
    "    \n",
    "    actions_with_event.append(action_with_event)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(840098, 840098)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(memories), len(actions_with_event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "memories.reverse()\n",
    "actions_with_event.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapoints = deque()\n",
    "for action_with_event in actions_with_event:\n",
    "    datapoint = Datapoint(\n",
    "        network_input=action_with_event.state,\n",
    "        action=action_with_event.action,\n",
    "        discounted_reward=action_with_event.discounted_reward\n",
    "    )\n",
    "    datapoints.append(datapoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"training_data_solo_cleaned.pt\", \"wb\") as f:\n",
    "    pickle.dump(datapoints, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
